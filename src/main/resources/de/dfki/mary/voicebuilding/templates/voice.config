# Auto-generated config file for voice ${voice.name}

name = ${voice.name}
locale = ${voice.locale}

####################################################################
####################### Module settings  ###########################
####################################################################
# For keys ending in ".list", values will be appended across config files,
# so that .list keys can occur in several config files.
# For all other keys, values will be copied to the global config, so
# keys should be unique across config files.

unitselection.voices.list = ${voice.name}

# If this setting is not present, a default value of 0 is assumed.
# More means higher assumed quality.
voice.${voice.name}.wants.to.be.default = ${voice.wantsToBeDefault}


# Set your voice specifications
voice.${voice.name}.gender = ${voice.gender}
voice.${voice.name}.locale = ${voice.locale}
voice.${voice.name}.domain = general
voice.${voice.name}.samplingRate = ${voice.samplingRate}

# Relative weight of the target cost function vs. the join cost function
voice.${voice.name}.viterbi.wTargetCosts = 0.7

# Beam size in dynamic programming: smaller => faster but worse quality.
# (set to -1 to disable beam search; very slow but best available quality)
voice.${voice.name}.viterbi.beamsize = 100

# Java classes to use for the various unit selection components
voice.${voice.name}.databaseClass            = marytts.unitselection.data.DiphoneUnitDatabase
voice.${voice.name}.selectorClass            = marytts.unitselection.select.DiphoneUnitSelector
voice.${voice.name}.concatenatorClass        = marytts.unitselection.concat.OverlapUnitConcatenator
voice.${voice.name}.targetCostClass          = marytts.unitselection.select.DiphoneFFRTargetCostFunction
voice.${voice.name}.joinCostClass            = marytts.unitselection.select.JoinCostFeatures
voice.${voice.name}.unitReaderClass          = marytts.unitselection.data.UnitFileReader
voice.${voice.name}.cartReaderClass          = marytts.cart.io.MARYCartReader
voice.${voice.name}.audioTimelineReaderClass = marytts.unitselection.data.TimelineReader

# Voice-specific files
voice.${voice.name}.featureFile       = MARY_BASE/lib/voices/${voice.name}/halfphoneFeatures_ac.mry
voice.${voice.name}.targetCostWeights = jar:/marytts/voice/${voice.nameCamelCase}/halfphoneUnitFeatureDefinition_ac.txt
voice.${voice.name}.joinCostFile      = MARY_BASE/lib/voices/${voice.name}/joinCostFeatures.mry
voice.${voice.name}.joinCostWeights   = jar:/marytts/voice/${voice.nameCamelCase}/joinCostWeights.txt
voice.${voice.name}.unitsFile         = MARY_BASE/lib/voices/${voice.name}/halfphoneUnits.mry
voice.${voice.name}.cartFile          = jar:/marytts/voice/${voice.nameCamelCase}/cart.mry
voice.${voice.name}.audioTimelineFile = MARY_BASE/lib/voices/${voice.name}/timeline_waveforms.mry
voice.${voice.name}.basenameTimeline  = MARY_BASE/lib/voices/${voice.name}/timeline_basenames.mry

# Modules to use for predicting acoustic target features for this voice:

voice.${voice.name}.acousticModels = duration F0 midF0 rightF0

voice.${voice.name}.duration.model = cart
voice.${voice.name}.duration.data = jar:/marytts/voice/${voice.nameCamelCase}/dur.tree
voice.${voice.name}.duration.attribute = d

voice.${voice.name}.F0.model = cart
voice.${voice.name}.F0.data = jar:/marytts/voice/${voice.nameCamelCase}/f0.left.tree
voice.${voice.name}.F0.attribute = f0
voice.${voice.name}.F0.attribute.format = (0,%.0f)
voice.${voice.name}.F0.predictFrom = firstVowels
voice.${voice.name}.F0.applyTo = firstVoicedSegments

voice.${voice.name}.midF0.model = cart
voice.${voice.name}.midF0.data = jar:/marytts/voice/${voice.nameCamelCase}/f0.mid.tree
voice.${voice.name}.midF0.attribute = f0
voice.${voice.name}.midF0.attribute.format = (50,%.0f)
voice.${voice.name}.midF0.predictFrom = firstVowels
voice.${voice.name}.midF0.applyTo = firstVowels

voice.${voice.name}.rightF0.model = cart
voice.${voice.name}.rightF0.data = jar:/marytts/voice/${voice.nameCamelCase}/f0.right.tree
voice.${voice.name}.rightF0.attribute = f0
voice.${voice.name}.rightF0.attribute.format = (100,%.0f)
voice.${voice.name}.rightF0.predictFrom = firstVowels
voice.${voice.name}.rightF0.applyTo = lastVoicedSegments
